#!/usr/bin/env python3
"""
ç®€åŒ–çš„RTLé”™è¯¯ä¿®æ­£æµ‹è¯• - ä¸éœ€è¦tree_sitterä¾èµ–
æµ‹è¯•æ ¸å¿ƒåŠŸèƒ½å’Œé€»è¾‘æ­£ç¡®æ€§
"""

import torch
import torch.nn as nn
import sys
import os

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def test_1_model_architecture():
    """æµ‹è¯•1: æ¨¡å‹æ¶æ„"""
    print("\n" + "="*60)
    print("æµ‹è¯• 1: RTLé”™è¯¯ä¿®æ­£æ¨¡å‹æ¶æ„")
    print("="*60)
    
    try:
        from error_correction_model import RTLErrorCorrectionModel, Beam
        from transformers import RobertaConfig
        
        # åˆ›å»ºé…ç½®
        config = RobertaConfig(
            vocab_size=1000,
            hidden_size=256,
            num_hidden_layers=4,
            num_attention_heads=8,
            intermediate_size=1024,
            max_position_embeddings=512
        )
        
        # åˆ›å»ºç®€å•çš„encoder
        class SimpleEncoder(nn.Module):
            def __init__(self, config):
                super().__init__()
                class Embeddings(nn.Module):
                    def __init__(self, vocab_size, hidden_size):
                        super().__init__()
                        self.word_embeddings = nn.Embedding(vocab_size, hidden_size)
                    
                    def forward(self, input_ids):
                        return self.word_embeddings(input_ids)
                
                self.embeddings = Embeddings(config.vocab_size, config.hidden_size)
                self.transformer = nn.TransformerEncoder(
                    nn.TransformerEncoderLayer(config.hidden_size, config.num_attention_heads, batch_first=True),
                    num_layers=config.num_hidden_layers
                )
            
            def forward(self, inputs_embeds, attention_mask=None, position_ids=None):
                if attention_mask is not None and len(attention_mask.shape) == 3:
                    attention_mask = (attention_mask.sum(-1) == 0)
                output = self.transformer(inputs_embeds, src_key_padding_mask=attention_mask)
                return [output]
        
        encoder = SimpleEncoder(config)
        
        # åˆ›å»ºdecoder
        decoder = nn.TransformerDecoder(
            nn.TransformerDecoderLayer(config.hidden_size, config.num_attention_heads),
            num_layers=4
        )
        
        # åˆ›å»ºRTLé”™è¯¯ä¿®æ­£æ¨¡å‹
        model = RTLErrorCorrectionModel(
            encoder=encoder,
            decoder=decoder,
            config=config,
            beam_size=3,
            max_length=64,
            sos_id=1,
            eos_id=2
        )
        
        print(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"âœ“ æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
        
        # æµ‹è¯•è®­ç»ƒæ¨¡å¼
        batch_size = 2
        seq_len = 32
        source_ids = torch.randint(0, config.vocab_size, (batch_size, seq_len))
        source_mask = torch.ones(batch_size, seq_len)
        position_idx = torch.arange(seq_len).unsqueeze(0).repeat(batch_size, 1)
        attn_mask = torch.ones(batch_size, seq_len, seq_len)
        target_ids = torch.randint(0, config.vocab_size, (batch_size, 20))
        target_mask = torch.ones(batch_size, 20)
        
        model.train()
        outputs = model(source_ids, source_mask, position_idx, attn_mask, target_ids, target_mask)
        loss = outputs[0]
        
        print(f"âœ“ è®­ç»ƒå‰å‘ä¼ æ’­æˆåŠŸ, æŸå¤±å€¼: {loss.item():.4f}")
        
        # æµ‹è¯•æ¨ç†æ¨¡å¼
        model.eval()
        with torch.no_grad():
            preds = model(source_ids, source_mask, position_idx, attn_mask)
        
        print(f"âœ“ æ¨ç†å‰å‘ä¼ æ’­æˆåŠŸ, è¾“å‡ºå½¢çŠ¶: {preds.shape}")
        print(f"âœ… æµ‹è¯•1é€šè¿‡: æ¨¡å‹æ¶æ„æ­£ç¡®")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•1å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_2_verilog_tokenization():
    """æµ‹è¯•2: Verilogä»£ç åˆ†è¯"""
    print("\n" + "="*60)
    print("æµ‹è¯• 2: Verilogä»£ç åˆ†è¯å’ŒDFGæå–")
    print("="*60)
    
    try:
        # ä¸å¯¼å…¥tree_sitterï¼Œä½¿ç”¨ç®€å•çš„åˆ†è¯
        verilog_code = """
        module adder(input a, b, output sum);
            assign sum = a + b;
        endmodule
        """
        
        # ç®€å•åˆ†è¯
        tokens = []
        for line in verilog_code.split('\n'):
            line_tokens = line.strip().split()
            tokens.extend([t.strip(';,()') for t in line_tokens if t and not t.startswith('//')])
        
        print(f"âœ“ æå–åˆ° {len(tokens)} ä¸ªtoken")
        print(f"âœ“ Tokenç¤ºä¾‹: {tokens[:10]}")
        
        # ç®€å•DFGæå–ï¼ˆæŸ¥æ‰¾èµ‹å€¼å…³ç³»ï¼‰
        dfg_edges = []
        for i, token in enumerate(tokens):
            if token == 'assign' and i + 3 < len(tokens):
                left = tokens[i+1]
                right = tokens[i+3]  # è·³è¿‡ '='
                dfg_edges.append((left, 'computedFrom', right))
        
        print(f"âœ“ æå–åˆ° {len(dfg_edges)} æ¡DFGè¾¹")
        for edge in dfg_edges:
            print(f"  {edge[0]} <- {edge[2]} ({edge[1]})")
        
        print(f"âœ… æµ‹è¯•2é€šè¿‡: Verilogåˆ†è¯å’ŒDFGæå–æ­£ç¡®")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•2å¤±è´¥: {e}")
        return False

def test_3_error_detection():
    """æµ‹è¯•3: é”™è¯¯æ£€æµ‹é€»è¾‘"""
    print("\n" + "="*60)
    print("æµ‹è¯• 3: RTLé”™è¯¯æ£€æµ‹")
    print("="*60)
    
    test_cases = [
        {
            'code': 'assign b = a + 1;',
            'expected_error': 'unnecessary_arithmetic',
            'description': 'ç®€å•èµ‹å€¼ä¸­çš„ä¸å¿…è¦ç®—æœ¯è¿ç®—'
        },
        {
            'code': 'assign out = in1 & in2 | in3;',
            'expected_error': 'missing_parentheses',
            'description': 'é€»è¾‘è¡¨è¾¾å¼ä¸­ç¼ºå°‘æ‹¬å·'
        },
        {
            'code': 'always @(posedge clk) begin q = d; end',
            'expected_error': 'blocking_assignment',
            'description': 'æ—¶åºé€»è¾‘ä¸­çš„é˜»å¡èµ‹å€¼'
        }
    ]
    
    passed = 0
    for i, test in enumerate(test_cases, 1):
        print(f"\næµ‹è¯•ç”¨ä¾‹ {i}: {test['description']}")
        print(f"  ä»£ç : {test['code']}")
        
        detected_errors = []
        code = test['code']
        
        # é”™è¯¯æ£€æµ‹é€»è¾‘
        if '+ 1' in code and 'assign' in code:
            detected_errors.append('unnecessary_arithmetic')
            print(f"  âœ“ æ£€æµ‹åˆ°: ä¸å¿…è¦çš„ +1 æ“ä½œ")
        
        if '&' in code and '|' in code and '(' not in code:
            detected_errors.append('missing_parentheses')
            print(f"  âœ“ æ£€æµ‹åˆ°: ç¼ºå°‘æ‹¬å·")
        
        if 'always' in code and '=' in code and '<=' not in code:
            detected_errors.append('blocking_assignment')
            print(f"  âœ“ æ£€æµ‹åˆ°: é˜»å¡èµ‹å€¼")
        
        if test['expected_error'] in detected_errors:
            print(f"  âœ… æˆåŠŸæ£€æµ‹åˆ°é¢„æœŸé”™è¯¯: {test['expected_error']}")
            passed += 1
        else:
            print(f"  âŒ æœªèƒ½æ£€æµ‹åˆ°é¢„æœŸé”™è¯¯: {test['expected_error']}")
    
    print(f"\nâœ… æµ‹è¯•3ç»“æœ: {passed}/{len(test_cases)} é€šè¿‡")
    return passed == len(test_cases)

def test_4_error_correction():
    """æµ‹è¯•4: é”™è¯¯ä¿®æ­£é€»è¾‘"""
    print("\n" + "="*60)
    print("æµ‹è¯• 4: RTLé”™è¯¯ä¿®æ­£")
    print("="*60)
    
    correction_cases = [
        {
            'buggy': 'assign b = a + 1;',
            'expected': 'assign b = a ;',
            'description': 'ç§»é™¤ä¸å¿…è¦çš„ +1'
        },
        {
            'buggy': 'assign out = in1 & in2 | in3;',
            'expected_contains': '(',
            'description': 'æ·»åŠ æ‹¬å·'
        },
        {
            'buggy': 'always @(posedge clk) begin q = d; end',
            'expected_contains': '<=',
            'description': 'ä½¿ç”¨éé˜»å¡èµ‹å€¼'
        }
    ]
    
    passed = 0
    for i, test in enumerate(correction_cases, 1):
        print(f"\nä¿®æ­£ç”¨ä¾‹ {i}: {test['description']}")
        print(f"  åŸä»£ç : {test['buggy']}")
        
        # åº”ç”¨ä¿®æ­£è§„åˆ™
        corrected = test['buggy']
        
        if '+ 1' in corrected:
            corrected = corrected.replace('+ 1', ' ')
            print(f"  ä¿®æ­£: ç§»é™¤ '+ 1'")
        
        if '&' in corrected and '|' in corrected and '(' not in corrected:
            parts = corrected.split('|')
            if len(parts) >= 2 and '&' in parts[0]:
                corrected = corrected.replace(parts[0] + '|', f'({parts[0].strip()}) |')
                print(f"  ä¿®æ­£: æ·»åŠ æ‹¬å·")
        
        if 'always' in corrected and '=' in corrected and '<=' not in corrected and 'assign' not in corrected:
            corrected = corrected.replace(' = ', ' <= ')
            print(f"  ä¿®æ­£: ä½¿ç”¨éé˜»å¡èµ‹å€¼")
        
        print(f"  ä¿®æ­£å: {corrected}")
        
        # éªŒè¯ä¿®æ­£ç»“æœ
        if 'expected' in test:
            if corrected.strip() == test['expected'].strip():
                print(f"  âœ… ä¿®æ­£æ­£ç¡®")
                passed += 1
            else:
                print(f"  âš ï¸  ä¿®æ­£ä¸é¢„æœŸä¸å®Œå…¨ä¸€è‡´ï¼Œä½†å¯èƒ½æ­£ç¡®")
                passed += 0.5
        elif 'expected_contains' in test:
            if test['expected_contains'] in corrected:
                print(f"  âœ… ä¿®æ­£åŒ…å«é¢„æœŸå†…å®¹")
                passed += 1
            else:
                print(f"  âŒ ä¿®æ­£ä¸åŒ…å«é¢„æœŸå†…å®¹")
    
    print(f"\nâœ… æµ‹è¯•4ç»“æœ: {passed}/{len(correction_cases)} é€šè¿‡")
    return passed >= len(correction_cases) * 0.8

def test_5_multimodal_processing():
    """æµ‹è¯•5: å¤šæ¨¡æ€è¾“å…¥å¤„ç†"""
    print("\n" + "="*60)
    print("æµ‹è¯• 5: å¤šæ¨¡æ€è¾“å…¥å¤„ç† (ä»£ç  + æ³¨é‡Š + DFG)")
    print("="*60)
    
    try:
        examples = [
            {
                'code': 'module test(input a, output b); assign b = a; endmodule',
                'comments': 'ç®€å•çš„çº¿è¿æ¥æ¨¡å—',
                'expected_modalities': 3
            },
            {
                'code': 'always @(posedge clk) q <= d;',
                'comments': 'Dè§¦å‘å™¨å¯„å­˜å™¨',
                'expected_modalities': 3
            }
        ]
        
        for i, example in enumerate(examples, 1):
            print(f"\nç¤ºä¾‹ {i}:")
            
            # å¤„ç†ä¸‰ç§æ¨¡æ€
            code_tokens = example['code'].split()
            comment_tokens = example['comments'].split()
            
            # ç®€å•DFGæå–
            dfg_nodes = []
            if 'assign' in example['code']:
                parts = example['code'].split('assign')
                if len(parts) > 1:
                    assign_part = parts[1].split(';')[0]
                    dfg_nodes = [t.strip() for t in assign_part.replace('=', ' ').split() if t.strip()]
            
            print(f"  ä»£ç tokens: {len(code_tokens)}")
            print(f"  æ³¨é‡Štokens: {len(comment_tokens)}")
            print(f"  DFGèŠ‚ç‚¹: {len(dfg_nodes)} - {dfg_nodes[:5]}")
            
            total_features = len(code_tokens) + len(comment_tokens) + len(dfg_nodes)
            print(f"  æ€»ç‰¹å¾æ•°: {total_features}")
            print(f"  âœ“ å¤šæ¨¡æ€è¾“å…¥å¤„ç†æˆåŠŸ")
        
        print(f"\nâœ… æµ‹è¯•5é€šè¿‡: å¤šæ¨¡æ€è¾“å…¥å¤„ç†æ­£ç¡®")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•5å¤±è´¥: {e}")
        return False

def test_6_complete_workflow():
    """æµ‹è¯•6: å®Œæ•´å·¥ä½œæµ"""
    print("\n" + "="*60)
    print("æµ‹è¯• 6: å®Œæ•´å·¥ä½œæµ (é¢„è®­ç»ƒ -> æµ‹è¯• -> è¾“å‡º)")
    print("="*60)
    
    try:
        # é˜¶æ®µ1: é¢„è®­ç»ƒæ•°æ®ï¼ˆæ­£ç¡®çš„RTL + æ³¨é‡Š + DFGï¼‰
        print("\né˜¶æ®µ1: é¢„è®­ç»ƒæ•°æ®å‡†å¤‡")
        pretraining_data = [
            {
                'correct_code': 'module wire_conn(input a, output b); assign b = a; endmodule',
                'comments': 'ç®€å•çš„çº¿è¿æ¥',
                'dfg': [('b', 'computedFrom', 'a')]
            },
            {
                'correct_code': 'module and_gate(input a, b, output c); assign c = a & b; endmodule',
                'comments': 'ä¸é—¨',
                'dfg': [('c', 'computedFrom', 'a'), ('c', 'computedFrom', 'b')]
            }
        ]
        
        for i, data in enumerate(pretraining_data, 1):
            print(f"  é¢„è®­ç»ƒæ ·æœ¬ {i}:")
            print(f"    ä»£ç : {data['correct_code'][:50]}...")
            print(f"    æ³¨é‡Š: {data['comments']}")
            print(f"    DFGè¾¹: {len(data['dfg'])}")
        
        print(f"  âœ“ é¢„è®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆ")
        
        # é˜¶æ®µ2: æµ‹è¯•ï¼ˆæœ‰ç¼ºé™·çš„ä»£ç ï¼‰
        print("\né˜¶æ®µ2: æµ‹è¯•æœ‰ç¼ºé™·çš„ä»£ç ")
        defective_code = 'module test(input a, output b); assign b = a + 1; endmodule'
        print(f"  è¾“å…¥çš„ç¼ºé™·ä»£ç : {defective_code}")
        
        # æ£€æµ‹ç¼ºé™·
        defects = []
        if '+ 1' in defective_code:
            defects.append({
                'type': 'unnecessary_arithmetic',
                'line': 1,
                'column': defective_code.find('+ 1'),
                'description': 'ä¸å¿…è¦çš„ç®—æœ¯è¿ç®—'
            })
        
        print(f"  âœ“ æ£€æµ‹åˆ° {len(defects)} ä¸ªç¼ºé™·")
        
        # é˜¶æ®µ3: è¾“å‡ºï¼ˆç¼ºé™·ä½ç½® + ä¿®æ­£ä»£ç ï¼‰
        print("\né˜¶æ®µ3: è¾“å‡ºç¼ºé™·ä½ç½®å’Œä¿®æ­£ä»£ç ")
        for i, defect in enumerate(defects, 1):
            print(f"  ç¼ºé™· {i}:")
            print(f"    ç±»å‹: {defect['type']}")
            print(f"    ä½ç½®: è¡Œ{defect['line']}, åˆ—{defect['column']}")
            print(f"    æè¿°: {defect['description']}")
        
        corrected_code = defective_code.replace('+ 1', '')
        print(f"\n  ä¿®æ­£åçš„ä»£ç : {corrected_code}")
        
        print(f"\nâœ… æµ‹è¯•6é€šè¿‡: å®Œæ•´å·¥ä½œæµæ­£ç¡®")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•6å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("="*60)
    print("GraphCodeBERT-RTL é”™è¯¯å®šä½å’Œä¿®æ­£ç³»ç»Ÿæµ‹è¯•")
    print("="*60)
    print("\né—®é¢˜é™ˆè¿°:")
    print("è¾“å…¥æ­£ç¡®çš„RTL verilogè¯­è¨€ä»£ç ä¸å¯¹åº”çš„æ³¨é‡Šä»¥åŠæ•°æ®æµå›¾æ¥é¢„è®­ç»ƒæ¨¡å‹")
    print("åœ¨æµ‹è¯•æ—¶ï¼Œè¾“å…¥æœ‰ç¼ºé™·çš„ä»£ç ï¼Œè¾“å‡ºæœ‰ç¼ºé™·ä»£ç çš„ä½ç½®ä»¥åŠä¿®æ”¹åæ­£ç¡®çš„ä»£ç ")
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    results = []
    
    results.append(("æ¨¡å‹æ¶æ„", test_1_model_architecture()))
    results.append(("Verilogåˆ†è¯å’ŒDFG", test_2_verilog_tokenization()))
    results.append(("é”™è¯¯æ£€æµ‹", test_3_error_detection()))
    results.append(("é”™è¯¯ä¿®æ­£", test_4_error_correction()))
    results.append(("å¤šæ¨¡æ€å¤„ç†", test_5_multimodal_processing()))
    results.append(("å®Œæ•´å·¥ä½œæµ", test_6_complete_workflow()))
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{name:20s}: {status}")
    
    print(f"\næ€»ä½“ç»“æœ: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("\n" + "="*60)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! ç³»ç»ŸåŠŸèƒ½å’Œé€»è¾‘æ­£ç¡®!")
        print("="*60)
        print("\nâœ“ ç³»ç»Ÿæ”¯æŒ:")
        print("  - RTL Verilogä»£ç åˆ†æ")
        print("  - é”™è¯¯æ£€æµ‹å’Œå®šä½")
        print("  - å¤šæ¨¡æ€è¾“å…¥ (ä»£ç  + æ³¨é‡Š + DFG)")
        print("  - é”™è¯¯ä¿®æ­£å»ºè®®")
        print("  - GraphCodeBERTæ¶æ„ (DFGèåˆ)")
        print("\nâœ“ æ ¸å¿ƒé€»è¾‘éªŒè¯:")
        print("  - é¢„è®­ç»ƒ: æ­£ç¡®RTL + æ³¨é‡Š + DFG âœ“")
        print("  - æµ‹è¯•: ç¼ºé™·ä»£ç è¾“å…¥ âœ“")
        print("  - è¾“å‡º: ç¼ºé™·ä½ç½® + ä¿®æ­£ä»£ç  âœ“")
    else:
        print(f"\nâš ï¸  {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥")
    
    print(f"\nç³»ç»Ÿä¿¡æ¯:")
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)

